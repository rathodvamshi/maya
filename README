C:\Users\vamsh\Source\3_1\project_ps2\maya\Project-Maya2\frontend>npm i
C:\Users\vamsh\Source\3_1\project_ps2\maya\Project-Maya2\frontend>npm start
C:\Users\vamsh\Source\3_1\project_ps2\maya\Project-Maya2\backend>python -m venv venv
C:\Users\vamsh\Source\3_1\project_ps2\maya\Project-Maya2>venv\Scripts\activate


# MongoDB Configuration
DATABASE_URL=mongodb+srv://Rathodvamshi:Rathod369@cluster0.yihtilk.mongodb.net/Maya?retryWrites=true&w=majority

# JWT Secret Key
SECRET_KEY=Maya@369
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60
REFRESH_TOKEN_EXPIRE_DAYS=7

# Redis Configuration (optional)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# AI API Keys
GEMINI_API_KEYS=AIzaSyDBK6irtEJ4NIV4xonuMGY1a4mCZsj-sMw
COHERE_API_KEY=w8Fl5GawNhWC4ZyNmsnzn5efFa5HrnViT4CkjNwp
ANTHROPIC_API_KEY=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

API_MONTHLY_LIMIT=20

# Email Configuration
MAIL_USERNAME=rathodvamshi369@gmail.com
MAIL_PASSWORD=rzeo aocu krnh uyax
MAIL_FROM=rathodvamshi369@gmail.com
MAIL_PORT=587
MAIL_SERVER=smtp.gmail.com
MAIL_STARTTLS=True
MAIL_SSL_TLS=False




## 1. Built a Full-Stack Chat Session System Chats
We started by building the core feature: the ability for users to have multiple, distinct chat conversations.

Dynamic Sidebar: We replaced the static sidebar with a fully dynamic one that loads and displays a user's chat history from the database.

Backend API: We built new, secure API endpoints using FastAPI to create, retrieve, and delete chat sessions in your MongoDB database.

State Management: We refactored your main Dashboard.js component, turning it into a powerful manager for all chat and session-related states, making the UI responsive and bug-free.

## 2. Engineered a Multi-Layered AI Memory üß†
This was the biggest upgrade. We designed and implemented a sophisticated, three-tiered memory system, just like the ones used in major AI platforms.

Permanent Memory (MongoDB): Every single word of every conversation is now saved permanently in MongoDB. This is your "source of truth."

Long-Term Searchable Memory (Pinecone): We set up a background process using Celery that automatically summarizes inactive conversations and stores those summaries in a Pinecone vector database. This allows the AI to perform semantic search‚Äîfinding relevant context from past chats even if you don't remember which one it was in.

Intelligent Context: When you start a new chat, the AI now intelligently searches its long-term memory in Pinecone to see if any past conversations are relevant, giving it a seamless, continuous memory.

## 3. Created a Resilient, Multi-Provider AI Engine ‚öôÔ∏è
To make your app reliable and cost-effective, we completely removed the dependency on a single AI provider.

No More OpenAI: We removed all code related to OpenAI.

Fallback Chain: Your app now uses a fallback chain of AI models. It will try Gemini first. If that fails, it automatically tries Anthropic, and then Cohere as a final backup.

Smart "Circuit Breaker": To be highly efficient, if an AI provider fails, the system will temporarily stop trying to use it for 5 minutes. This prevents your app from wasting time on a service that is down and makes the fallback to the next provider almost instant.

## 4. Performed Extensive Debugging & Stabilization üõ†Ô∏è
Building a complex system always involves fixing issues. We methodically diagnosed and solved every problem that came up.

Fixed Backend Crashes: We resolved multiple server crashes, including configuration errors (AttributeError, ValidationError) and a critical PermissionError that was stopping your Celery background workers on Windows.

Eliminated Frontend Bugs: We fixed a TypeError that was crashing the chat window and stabilized the data-fetching logic to prevent infinite loading loops.

Corrected API & Environment Issues: We fixed API quota errors, vector dimension mismatches between the AI model and Pinecone, and ensured all your environment variables and dependencies are perfectly configured.